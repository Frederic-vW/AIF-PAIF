# Autoinformation

Entropy-based techniques for the analysis of symbolic time series, i.e. sequences of non-metric variables from a finite state space.
- Autoinformation (AIF): time-lagged mutual information coefficients
- Partial autoinformation (PAIF)
- Finite entropy rate

*Application examples:* (Hidden-) Markov Models, spin models (Ising, Potts,...), EEG microstate sequences.

This repo contains the code and the data examples used in the article:  
F. von Wegner, "Partial Autoinformation to Characterize Symbolic Sequences", Front Physiol (2018)  
https://doi.org/10.3389/fphys.2018.01382
